{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "IfJ8kMD0sR--"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Goal:** Reach the bottom right cell of the grid starting from top left cell\n",
        "\n",
        "**Note:** There are barriers in some of the cells so it might not always be possible to reach the goal\n",
        "\n",
        "**Reward:** 10 for reaching goal; 0 otherwise\n",
        "\n",
        "**Discount factor:** 0.9\n",
        "\n",
        "**Note:** Agent should try to reach goal ASAP otherwise the overall reward will get diluted"
      ],
      "metadata": {
        "id": "sjPMrZTruW8W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Value Iteration**"
      ],
      "metadata": {
        "id": "gUihXOHzERwu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MazeSolver:\n",
        "\n",
        "    def __init__(self, size, barrier_prob):\n",
        "        self.size = size # Size of square grid\n",
        "        self.barrier_prob = barrier_prob # Probability of a cell being a barrier\n",
        "        self.maze = np.zeros((size, size))  # 0 represents an empty cell\n",
        "        self.generate_maze()\n",
        "\n",
        "        # Start state: top left cell\n",
        "        self.start_state = (0, 0)\n",
        "        # Terminal state: bottom right cell\n",
        "        self.terminal_state = (size - 1, size - 1)\n",
        "\n",
        "    def generate_maze(self):\n",
        "        for i in range(self.size):\n",
        "            for j in range(self.size):\n",
        "                if np.random.rand() < self.barrier_prob:\n",
        "                    self.maze[i, j] = 1  # Barrier is represented using 1\n",
        "        self.maze[self.size-1, self.size-1] = 0  # This makes sure that terminal state is not a barrier\n",
        "        self.maze[0, 0] = 0  # This makes sure that start state is not a barrier\n",
        "        global my_maze\n",
        "        my_maze = self.maze\n",
        "        print(\"\\nInitial maze with barriers:\\n\")\n",
        "        self.print_initial_maze()\n",
        "\n",
        "    def is_solvable(self):\n",
        "        visited = set()\n",
        "\n",
        "        def dfs(x, y):\n",
        "            if not (0 <= x < self.size and 0 <= y < self.size) or my_maze[x, y] == 1 or (x, y) in visited:\n",
        "                return False\n",
        "\n",
        "            visited.add((x, y))\n",
        "\n",
        "            if (x, y) == self.terminal_state:\n",
        "                return True\n",
        "\n",
        "            directions = [(0, 1), (0, -1), (1, 0), (-1, 0)]\n",
        "\n",
        "            for dx, dy in directions:\n",
        "                if dfs(x + dx, y + dy):\n",
        "                    return True\n",
        "\n",
        "            return False\n",
        "\n",
        "        return dfs(*self.start_state)\n",
        "\n",
        "    def is_valid_move(self, x, y):\n",
        "        return 0 <= x < self.size and 0 <= y < self.size and self.maze[x, y] == 0\n",
        "\n",
        "    def value_iteration(self, discount_factor=0.9, theta=0.3, max_iterations=1000):\n",
        "        value_function = np.zeros((self.size, self.size))\n",
        "        for iteration in range(max_iterations):\n",
        "            print(f\"\\nValue Iteration - Iteration {iteration + 1}:\\n\")\n",
        "\n",
        "            delta = 0\n",
        "            for i in range(self.size):\n",
        "                for j in range(self.size):\n",
        "                    # If barrier skip\n",
        "                    if self.maze[i, j] == 1:\n",
        "                        continue\n",
        "                    v = value_function[i, j]\n",
        "                    # Value Iteration updates based on 1 step lookahed\n",
        "                    value_function[i, j] = self.calculate_max_value(i, j, value_function, discount_factor)\n",
        "                    delta = max(delta, abs(v - value_function[i, j])) # Delta captures the maximum difference in value function at any state\n",
        "\n",
        "            self.print_maze(value_function)\n",
        "\n",
        "            if delta < theta:\n",
        "                print('\\n=========================================\\n')\n",
        "                return value_function\n",
        "\n",
        "    def calculate_max_value(self, x, y, value_function, discount_factor):\n",
        "        max_value = float('-inf')\n",
        "        # Obtain the maximum value from the 4 actions\n",
        "        for action in range(4):\n",
        "            next_x, next_y = self.get_next_position(x, y, action)\n",
        "            if self.is_valid_move(next_x, next_y):\n",
        "                if x == self.size-1 and y == self.size-1:\n",
        "                    reward = 10\n",
        "                else:\n",
        "                    reward = 0\n",
        "\n",
        "                max_value = max(max_value,reward + discount_factor * value_function[next_x, next_y])\n",
        "\n",
        "        return max_value\n",
        "\n",
        "\n",
        "    def get_next_position(self, x, y, action):\n",
        "        if action == 0:  # Up\n",
        "            return x - 1, y\n",
        "        elif action == 1:  # Right\n",
        "            return x, y + 1\n",
        "        elif action == 2:  # Down\n",
        "            return x + 1, y\n",
        "        elif action == 3:  # Left\n",
        "            return x, y - 1\n",
        "\n",
        "    def print_maze(self, values):\n",
        "        for i in range(self.size):\n",
        "            for j in range(self.size):\n",
        "                cell = \"S\" if (i, j) == self.start_state else \"B\" if self.maze[i, j] == 1 else f\"{values[i, j]:.2f}\"\n",
        "                print(f\"{cell:6} |\", end=\"\")\n",
        "            print()\n",
        "\n",
        "    def print_initial_maze(self):\n",
        "        for i in range(self.size):\n",
        "            for j in range(self.size):\n",
        "                if (i, j) == (0,0):\n",
        "                    print(\"S    |\", end=\"\")\n",
        "                elif my_maze[i, j] == 1:\n",
        "                    print(\"B    |\", end=\"\")\n",
        "                else:\n",
        "                    print(f\"{my_maze[i, j]:.2f} |\", end=\"\")\n",
        "            print()\n",
        "\n",
        "    def getCommands(self):\n",
        "        # Value iteration is called for solving the maze\n",
        "        values = self.value_iteration()\n",
        "        commands = []\n",
        "        i,j=0,0\n",
        "        nexti,nextj = 0,0\n",
        "        while i!=self.size-1 or j!=self.size-1:\n",
        "            max = float('-inf')\n",
        "            maxDir = None\n",
        "            nexti=i\n",
        "            nextj=j\n",
        "            if i-1>0 and max<values[i-1][j]:\n",
        "                max = values[i-1][j]\n",
        "                maxDir='u'\n",
        "                nexti=i-1\n",
        "            if i+1<self.size and max<values[i+1][j]:\n",
        "                max = values[i+1][j]\n",
        "                maxDir='d'\n",
        "                nexti=i+1\n",
        "            if j-1>0 and max<values[i][j-1]:\n",
        "                max = values[i][j-1]\n",
        "                maxDir='l'\n",
        "                nextj=j-1\n",
        "                nexti=i\n",
        "            if j+1<self.size and max<values[i][j+1]:\n",
        "                max = values[i][j+1]\n",
        "                maxDir='r'\n",
        "                nextj=j+1\n",
        "                nexti=i\n",
        "\n",
        "            if maxDir is not None:\n",
        "                commands.append(maxDir)\n",
        "                i=nexti\n",
        "                j=nextj\n",
        "        return commands"
      ],
      "metadata": {
        "id": "T4NG_c9-cmOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "size = int(input(\"Enter the maze size: \"))\n",
        "barrier_prob = float(input(\"Enter the barrier probability: \"))\n",
        "maze_solver = MazeSolver(size, barrier_prob)\n",
        "solvable = maze_solver.is_solvable()\n",
        "\n",
        "if(solvable):\n",
        "  optimal_path = maze_solver.getCommands()\n",
        "  print(\"Path to goal:\")\n",
        "  print(optimal_path)\n",
        "  print(f\"Cost of path: {len(optimal_path)}\")\n",
        "else:\n",
        "  print(\"Too many barriers. Solution does not exist.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOBEjEk8xbsF",
        "outputId": "a3d7136b-ef15-40b5-a3ca-89c912df94d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the maze size: 4\n",
            "Enter the barrier probability: 0.2\n",
            "\n",
            "Initial maze with barriers:\n",
            "\n",
            "S    |0.00 |B    |0.00 |\n",
            "0.00 |0.00 |0.00 |0.00 |\n",
            "0.00 |0.00 |0.00 |0.00 |\n",
            "0.00 |B    |0.00 |0.00 |\n",
            "\n",
            "Value Iteration - Iteration 1:\n",
            "\n",
            "S      |0.00   |B      |0.00   |\n",
            "0.00   |0.00   |0.00   |0.00   |\n",
            "0.00   |0.00   |0.00   |0.00   |\n",
            "0.00   |B      |0.00   |10.00  |\n",
            "\n",
            "Value Iteration - Iteration 2:\n",
            "\n",
            "S      |0.00   |B      |0.00   |\n",
            "0.00   |0.00   |0.00   |0.00   |\n",
            "0.00   |0.00   |0.00   |9.00   |\n",
            "0.00   |B      |9.00   |18.10  |\n",
            "\n",
            "Value Iteration - Iteration 3:\n",
            "\n",
            "S      |0.00   |B      |0.00   |\n",
            "0.00   |0.00   |0.00   |8.10   |\n",
            "0.00   |0.00   |8.10   |16.29  |\n",
            "0.00   |B      |16.29  |24.66  |\n",
            "\n",
            "Value Iteration - Iteration 4:\n",
            "\n",
            "S      |0.00   |B      |7.29   |\n",
            "0.00   |0.00   |7.29   |14.66  |\n",
            "0.00   |7.29   |14.66  |22.19  |\n",
            "0.00   |B      |22.19  |29.98  |\n",
            "\n",
            "Value Iteration - Iteration 5:\n",
            "\n",
            "S      |0.00   |B      |13.19  |\n",
            "0.00   |6.56   |13.19  |19.98  |\n",
            "6.56   |13.19  |19.98  |26.98  |\n",
            "5.90   |B      |26.98  |34.28  |\n",
            "\n",
            "Value Iteration - Iteration 6:\n",
            "\n",
            "S      |5.90   |B      |17.98  |\n",
            "5.90   |11.88  |17.98  |24.28  |\n",
            "11.88  |17.98  |24.28  |30.85  |\n",
            "10.69  |B      |30.85  |37.77  |\n",
            "\n",
            "Value Iteration - Iteration 7:\n",
            "\n",
            "S      |10.69  |B      |21.85  |\n",
            "10.69  |16.18  |21.85  |27.77  |\n",
            "16.18  |21.85  |27.77  |33.99  |\n",
            "14.56  |B      |33.99  |40.59  |\n",
            "\n",
            "Value Iteration - Iteration 8:\n",
            "\n",
            "S      |14.56  |B      |24.99  |\n",
            "14.56  |19.67  |24.99  |30.59  |\n",
            "19.67  |24.99  |30.59  |36.53  |\n",
            "17.70  |B      |36.53  |42.88  |\n",
            "\n",
            "Value Iteration - Iteration 9:\n",
            "\n",
            "S      |17.70  |B      |27.53  |\n",
            "17.70  |22.49  |27.53  |32.88  |\n",
            "22.49  |27.53  |32.88  |38.59  |\n",
            "20.24  |B      |38.59  |44.73  |\n",
            "\n",
            "Value Iteration - Iteration 10:\n",
            "\n",
            "S      |20.24  |B      |29.59  |\n",
            "20.24  |24.78  |29.59  |34.73  |\n",
            "24.78  |29.59  |34.73  |40.26  |\n",
            "22.30  |B      |40.26  |46.23  |\n",
            "\n",
            "Value Iteration - Iteration 11:\n",
            "\n",
            "S      |22.30  |B      |31.26  |\n",
            "22.30  |26.63  |31.26  |36.23  |\n",
            "26.63  |31.26  |36.23  |41.61  |\n",
            "23.97  |B      |41.61  |47.45  |\n",
            "\n",
            "Value Iteration - Iteration 12:\n",
            "\n",
            "S      |23.97  |B      |32.61  |\n",
            "23.97  |28.13  |32.61  |37.45  |\n",
            "28.13  |32.61  |37.45  |42.70  |\n",
            "25.32  |B      |42.70  |48.43  |\n",
            "\n",
            "Value Iteration - Iteration 13:\n",
            "\n",
            "S      |25.32  |B      |33.70  |\n",
            "25.32  |29.35  |33.70  |38.43  |\n",
            "29.35  |33.70  |38.43  |43.59  |\n",
            "26.41  |B      |43.59  |49.23  |\n",
            "\n",
            "Value Iteration - Iteration 14:\n",
            "\n",
            "S      |26.41  |B      |34.59  |\n",
            "26.41  |30.33  |34.59  |39.23  |\n",
            "30.33  |34.59  |39.23  |44.31  |\n",
            "27.30  |B      |44.31  |49.88  |\n",
            "\n",
            "Value Iteration - Iteration 15:\n",
            "\n",
            "S      |27.30  |B      |35.31  |\n",
            "27.30  |31.13  |35.31  |39.88  |\n",
            "31.13  |35.31  |39.88  |44.89  |\n",
            "28.02  |B      |44.89  |50.40  |\n",
            "\n",
            "Value Iteration - Iteration 16:\n",
            "\n",
            "S      |28.02  |B      |35.89  |\n",
            "28.02  |31.78  |35.89  |40.40  |\n",
            "31.78  |35.89  |40.40  |45.36  |\n",
            "28.60  |B      |45.36  |50.82  |\n",
            "\n",
            "Value Iteration - Iteration 17:\n",
            "\n",
            "S      |28.60  |B      |36.36  |\n",
            "28.60  |32.30  |36.36  |40.82  |\n",
            "32.30  |36.36  |40.82  |45.74  |\n",
            "29.07  |B      |45.74  |51.17  |\n",
            "\n",
            "Value Iteration - Iteration 18:\n",
            "\n",
            "S      |29.07  |B      |36.74  |\n",
            "29.07  |32.72  |36.74  |41.17  |\n",
            "32.72  |36.74  |41.17  |46.05  |\n",
            "29.45  |B      |46.05  |51.45  |\n",
            "\n",
            "Value Iteration - Iteration 19:\n",
            "\n",
            "S      |29.45  |B      |37.05  |\n",
            "29.45  |33.07  |37.05  |41.45  |\n",
            "33.07  |37.05  |41.45  |46.30  |\n",
            "29.76  |B      |46.30  |51.67  |\n",
            "\n",
            "Value Iteration - Iteration 20:\n",
            "\n",
            "S      |29.76  |B      |37.30  |\n",
            "29.76  |33.35  |37.30  |41.67  |\n",
            "33.35  |37.30  |41.67  |46.50  |\n",
            "30.01  |B      |46.50  |51.85  |\n",
            "\n",
            "Value Iteration - Iteration 21:\n",
            "\n",
            "S      |30.01  |B      |37.50  |\n",
            "30.01  |33.57  |37.50  |41.85  |\n",
            "33.57  |37.50  |41.85  |46.67  |\n",
            "30.21  |B      |46.67  |52.00  |\n",
            "\n",
            "=========================================\n",
            "\n",
            "Path to goal:\n",
            "['d', 'd', 'r', 'r', 'd', 'r']\n",
            "Cost of path: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mwGCVdCT_D5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation 1:** Multiple optimal policies but unique optimal value function\n",
        "\n",
        "**Observation 2:** Length of optimal path = 2 * (maze_size - 1)"
      ],
      "metadata": {
        "id": "7SFTIB-48nYJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Policy Iteration**"
      ],
      "metadata": {
        "id": "uR2tWFrhEYr_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MazeSolver:\n",
        "    def __init__(self, size, barrier_prob):\n",
        "        self.size = size # Size of square grid\n",
        "        self.barrier_prob = barrier_prob # Probability of a cell being a barrier\n",
        "        self.maze = np.zeros((size, size))  # 0 represents an empty cell\n",
        "        self.generate_maze()\n",
        "\n",
        "        # Start state: top left cell\n",
        "        self.start_state = (0, 0)\n",
        "        # Terminal state: bottom right cell\n",
        "        self.terminal_state = (size - 1, size - 1)\n",
        "\n",
        "        # Initialize an arbitrary policy\n",
        "        self.policy = np.random.randint(0, 4, size=(size, size))  # 0: Up, 1: Right, 2: Down, 3: Left\n",
        "\n",
        "    def generate_maze(self):\n",
        "        for i in range(self.size - 1):\n",
        "            for j in range(self.size - 1):\n",
        "                if i != 0 or j != 0: # This makes sure that start state is not a barrier\n",
        "                    if np.random.rand() < self.barrier_prob:\n",
        "                        self.maze[i, j] = -1  # -1 represents a barrier\n",
        "        global my_maze\n",
        "        my_maze = self.maze\n",
        "        print(\"\\nInitial maze with barriers:\\n\")\n",
        "        print(self.maze)\n",
        "\n",
        "    def is_solvable(self):\n",
        "        visited = set()\n",
        "\n",
        "        def dfs(x, y):\n",
        "            if not (0 <= x < self.size and 0 <= y < self.size) or my_maze[x, y] == -1 or (x, y) in visited:\n",
        "                return False\n",
        "\n",
        "            visited.add((x, y))\n",
        "\n",
        "            if (x, y) == self.terminal_state:\n",
        "                return True\n",
        "\n",
        "            directions = [(0, 1), (0, -1), (1, 0), (-1, 0)]\n",
        "\n",
        "            for dx, dy in directions:\n",
        "                if dfs(x + dx, y + dy):\n",
        "                    return True\n",
        "\n",
        "            return False\n",
        "\n",
        "        return dfs(*self.start_state)\n",
        "\n",
        "\n",
        "    def is_valid_move(self, x, y):\n",
        "        return 0 <= x < self.size and 0 <= y < self.size and self.maze[x, y] == 0\n",
        "\n",
        "    def policy_iteration(self, discount_factor=0.9, max_iterations=1000):\n",
        "        # Initialize an arbitrary value function\n",
        "        value_function = np.zeros((self.size, self.size))\n",
        "\n",
        "        for iteration in range(max_iterations):\n",
        "\n",
        "            # Policy Evaluation\n",
        "            value_function = self.evaluate_policy(value_function, discount_factor)\n",
        "\n",
        "            # Policy Improvement\n",
        "            new_policy = self.improve_policy(value_function, discount_factor)\n",
        "\n",
        "            # Check if the policy has converged\n",
        "            if np.array_equal(new_policy, self.policy):\n",
        "                print(\"\\nPolicy has converged. Final value function:\\n\")\n",
        "                value_function = self.evaluate_policy(value_function, discount_factor)\n",
        "                self.print_maze_value(value_function)\n",
        "                print('\\n=========================================\\n')\n",
        "                break\n",
        "            print(f\"\\nPolicy Iteration - Iteration {iteration + 1}:\\n\")\n",
        "            self.print_maze_value(value_function)\n",
        "            self.policy = new_policy\n",
        "            print(f\"\\nGreedy policy at Iteration {iteration + 1}:\\n\")\n",
        "            self.print_maze(self.policy)\n",
        "\n",
        "\n",
        "    def evaluate_policy(self, value_function, discount_factor):\n",
        "        for _ in range(1000):  # The number of iterations can be modified\n",
        "            for i in range(self.size):\n",
        "                for j in range(self.size):\n",
        "                    # If barrier, skip\n",
        "                    if self.maze[i, j] == -1:\n",
        "                        continue\n",
        "\n",
        "                    action = self.policy[i, j]\n",
        "                    next_x, next_y = self.get_next_position(i, j, action)\n",
        "\n",
        "                    if self.is_valid_move(next_x, next_y):\n",
        "                        reward = 0\n",
        "                        if (i, j) == self.terminal_state:\n",
        "                            reward = 10\n",
        "\n",
        "                        # Update value function based on policy\n",
        "                        value_function[i, j] = reward + discount_factor * value_function[next_x, next_y]\n",
        "\n",
        "        return value_function\n",
        "\n",
        "    def improve_policy(self, value_function, discount_factor):\n",
        "        new_policy = np.zeros((self.size, self.size))\n",
        "\n",
        "        for i in range(self.size):\n",
        "            for j in range(self.size):\n",
        "                if self.maze[i, j] == -1:\n",
        "                    # Do not modify barrier\n",
        "                    new_policy[i,j] = -1\n",
        "                    continue\n",
        "\n",
        "                # Try all possible actions and choose the one with the highest expected value\n",
        "                max_action = None\n",
        "                max_value = float('-inf')\n",
        "\n",
        "                for action in range(4):\n",
        "                    next_x, next_y = self.get_next_position(i, j, action)\n",
        "\n",
        "                    if self.is_valid_move(next_x, next_y):\n",
        "                        reward = 0\n",
        "                        if (i, j) == self.terminal_state:\n",
        "                            reward = 10\n",
        "\n",
        "                        expected_value = reward + discount_factor * value_function[next_x, next_y]\n",
        "\n",
        "                        if expected_value > max_value:\n",
        "                            max_value = expected_value\n",
        "                            max_action = action\n",
        "\n",
        "                if max_action is not None:\n",
        "\n",
        "                    new_policy[i, j] = max_action\n",
        "\n",
        "        return new_policy\n",
        "\n",
        "    def get_next_position(self, x, y, action):\n",
        "        if action == 0:  # Up\n",
        "            return x - 1, y\n",
        "        elif action == 1:  # Right\n",
        "            return x, y + 1\n",
        "        elif action == 2:  # Down\n",
        "            return x + 1, y\n",
        "        elif action == 3:  # Left\n",
        "            return x, y - 1\n",
        "\n",
        "    def print_maze(self, policy):\n",
        "        for i in range(self.size):\n",
        "            for j in range(self.size):\n",
        "                if (i, j) == self.terminal_state:\n",
        "                    print(\"T    |\", end=\"\")\n",
        "                elif self.maze[i, j] == -1:\n",
        "                    print(\"B    |\", end=\"\")\n",
        "                else:\n",
        "                    action_str = \"↑\" if policy[i, j] == 0 else \"→\" if policy[i, j] == 1 else \"↓\" if policy[i, j] == 2 else \"←\"\n",
        "                    print(f\"{action_str}    |\", end=\"\")\n",
        "            print()\n",
        "\n",
        "    def print_maze_value(self, values):\n",
        "        for i in range(self.size):\n",
        "            for j in range(self.size):\n",
        "                cell = \"S\" if (i, j) == self.start_state else \"B\" if self.maze[i, j] == 1 else f\"{values[i, j]:.2f}\"\n",
        "                print(f\"{cell:6} |\", end=\"\")\n",
        "            print()\n",
        "\n",
        "def find_optimal_path_with_values(value_array):\n",
        "    rows, cols = value_array.shape\n",
        "    optimal_path = []\n",
        "\n",
        "    current_position = (0, 0)\n",
        "    terminal_state = (rows - 1, cols - 1)\n",
        "\n",
        "    while current_position != terminal_state:\n",
        "        i, j = current_position\n",
        "        if value_array[i,j] == 0:\n",
        "            direction = 'U'\n",
        "            next_position = (i-1,j)\n",
        "            optimal_path.append(direction)\n",
        "        elif value_array[i,j] == 1:\n",
        "            direction = 'R'\n",
        "            next_position = (i,j+1)\n",
        "            optimal_path.append(direction)\n",
        "        elif value_array[i,j] == 2:\n",
        "            next_position = (i+1,j)\n",
        "            direction = 'D'\n",
        "            optimal_path.append(direction)\n",
        "        elif value_array[i,j] == -1:\n",
        "                return -1\n",
        "        else:\n",
        "            direction = 'L'\n",
        "            next_position = (i,j-1)\n",
        "            optimal_path.append(direction)\n",
        "\n",
        "        current_position = next_position\n",
        "\n",
        "    return optimal_path"
      ],
      "metadata": {
        "id": "Z5Hf07TLEb3V"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "size = int(input(\"Enter the maze size: \"))\n",
        "barrier_prob = float(input(\"Enter the barrier probability: \"))\n",
        "maze_solver = MazeSolver(size, barrier_prob)\n",
        "solvable = maze_solver.is_solvable()\n",
        "\n",
        "if(solvable):\n",
        "  maze_solver.policy_iteration()\n",
        "  pas = find_optimal_path_with_values(maze_solver.policy)\n",
        "  print(\"Path to goal:\")\n",
        "  print(pas)\n",
        "  print(f\"Cost of path: {len(pas)}\")\n",
        "else:\n",
        "  print(\"Too many barriers. Solution does not exist.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGcTCrNvFd5d",
        "outputId": "acf1b780-709f-4a7f-d719-06c4e0d5efb9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the maze size: 5\n",
            "Enter the barrier probability: 0.1\n",
            "\n",
            "Initial maze with barriers:\n",
            "\n",
            "[[ 0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1.  0.]\n",
            " [ 0.  0.  0.  0.  0.]]\n",
            "\n",
            "Policy Iteration - Iteration 1:\n",
            "\n",
            "S      |0.00   |0.00   |0.00   |0.00   |\n",
            "0.00   |0.00   |0.00   |0.00   |0.00   |\n",
            "0.00   |0.00   |0.00   |0.00   |0.00   |\n",
            "0.00   |0.00   |0.00   |0.00   |47.37  |\n",
            "0.00   |0.00   |0.00   |0.00   |52.63  |\n",
            "\n",
            "Greedy policy at Iteration 1:\n",
            "\n",
            "→    |→    |→    |→    |↓    |\n",
            "↑    |↑    |↑    |↑    |↑    |\n",
            "↑    |↑    |↑    |↑    |↓    |\n",
            "↑    |↑    |↑    |B    |↓    |\n",
            "↑    |↑    |↑    |→    |T    |\n",
            "\n",
            "Policy Iteration - Iteration 2:\n",
            "\n",
            "S      |0.00   |0.00   |0.00   |0.00   |\n",
            "0.00   |0.00   |0.00   |0.00   |0.00   |\n",
            "0.00   |0.00   |0.00   |0.00   |42.63  |\n",
            "0.00   |0.00   |0.00   |0.00   |47.37  |\n",
            "0.00   |0.00   |0.00   |47.37  |52.63  |\n",
            "\n",
            "Greedy policy at Iteration 2:\n",
            "\n",
            "→    |→    |→    |→    |↓    |\n",
            "↑    |↑    |↑    |↑    |↓    |\n",
            "↑    |↑    |↑    |→    |↓    |\n",
            "↑    |↑    |↑    |B    |↓    |\n",
            "↑    |↑    |→    |→    |T    |\n",
            "\n",
            "Policy Iteration - Iteration 3:\n",
            "\n",
            "S      |25.17  |27.97  |31.08  |34.53  |\n",
            "20.39  |22.66  |25.17  |27.97  |38.37  |\n",
            "18.35  |20.39  |22.66  |38.37  |42.63  |\n",
            "16.52  |18.35  |20.39  |0.00   |47.37  |\n",
            "14.86  |16.52  |42.63  |47.37  |52.63  |\n",
            "\n",
            "Greedy policy at Iteration 3:\n",
            "\n",
            "→    |→    |→    |→    |↓    |\n",
            "↑    |↑    |↑    |→    |↓    |\n",
            "↑    |↑    |→    |→    |↓    |\n",
            "↑    |↑    |↓    |B    |↓    |\n",
            "↑    |→    |→    |→    |T    |\n",
            "\n",
            "Policy Iteration - Iteration 4:\n",
            "\n",
            "S      |25.17  |27.97  |31.08  |34.53  |\n",
            "20.39  |22.66  |25.17  |34.53  |38.37  |\n",
            "18.35  |20.39  |34.53  |38.37  |42.63  |\n",
            "16.52  |18.35  |38.37  |0.00   |47.37  |\n",
            "14.86  |38.37  |42.63  |47.37  |52.63  |\n",
            "\n",
            "Greedy policy at Iteration 4:\n",
            "\n",
            "→    |→    |→    |→    |↓    |\n",
            "↑    |↑    |→    |→    |↓    |\n",
            "↑    |→    |→    |→    |↓    |\n",
            "↑    |→    |↓    |B    |↓    |\n",
            "→    |→    |→    |→    |T    |\n",
            "\n",
            "Policy Iteration - Iteration 5:\n",
            "\n",
            "S      |25.17  |27.97  |31.08  |34.53  |\n",
            "20.39  |22.66  |31.08  |34.53  |38.37  |\n",
            "18.35  |31.08  |34.53  |38.37  |42.63  |\n",
            "16.52  |34.53  |38.37  |0.00   |47.37  |\n",
            "34.53  |38.37  |42.63  |47.37  |52.63  |\n",
            "\n",
            "Greedy policy at Iteration 5:\n",
            "\n",
            "→    |→    |→    |→    |↓    |\n",
            "↑    |→    |→    |→    |↓    |\n",
            "→    |→    |→    |→    |↓    |\n",
            "→    |→    |↓    |B    |↓    |\n",
            "→    |→    |→    |→    |T    |\n",
            "\n",
            "Policy Iteration - Iteration 6:\n",
            "\n",
            "S      |25.17  |27.97  |31.08  |34.53  |\n",
            "20.39  |27.97  |31.08  |34.53  |38.37  |\n",
            "27.97  |31.08  |34.53  |38.37  |42.63  |\n",
            "31.08  |34.53  |38.37  |0.00   |47.37  |\n",
            "34.53  |38.37  |42.63  |47.37  |52.63  |\n",
            "\n",
            "Greedy policy at Iteration 6:\n",
            "\n",
            "→    |→    |→    |→    |↓    |\n",
            "→    |→    |→    |→    |↓    |\n",
            "→    |→    |→    |→    |↓    |\n",
            "→    |→    |↓    |B    |↓    |\n",
            "→    |→    |→    |→    |T    |\n",
            "\n",
            "Policy has converged. Final value function:\n",
            "\n",
            "S      |25.17  |27.97  |31.08  |34.53  |\n",
            "25.17  |27.97  |31.08  |34.53  |38.37  |\n",
            "27.97  |31.08  |34.53  |38.37  |42.63  |\n",
            "31.08  |34.53  |38.37  |0.00   |47.37  |\n",
            "34.53  |38.37  |42.63  |47.37  |52.63  |\n",
            "\n",
            "=========================================\n",
            "\n",
            "Path to goal:\n",
            "['R', 'R', 'R', 'R', 'D', 'D', 'D', 'D']\n",
            "Cost of path: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g43hH6glHHHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation 1:** There could be multiple optimal policies\n",
        "\n",
        "**Observation 2:** Length of optimal path = 2 * (maze_size - 1)"
      ],
      "metadata": {
        "id": "Jjcop41mk0K6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uhy67yNSlB5S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}